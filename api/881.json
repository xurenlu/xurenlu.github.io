{"title":"hyer开发笔记之:HTMLParser不支持中文问题","zzzContent":"在开发<a title=\"hyer\" href=\"http://www.162cm.com/archives/703.html\" target=\"_blank\">hyer</a>的过程中，我发现<a href=\"http://www.crummy.com/software/BeautifulSoup/\">beautifulsoup</a>解析中文网页总是有问题。于是乎，我决定用tidy来在beautifulsoup之前做一个fix.没想到tidy的python极其不雅,首先tidy的强大在python版的<a href=\"http://utidylib.berlios.de/\">uTidylib</a>也完全感觉不到了，而且安装的时候时候还有错误。\n\n等tidy问题终于修正之后，发现大量的网页已经能用美味的汤[beautifulsoup]来解决了,但是仍然有一部分网页 不行。\n\n最终经过跟踪发现是在这里:(/usr/lib/python2.6/HTMLParser.py):\n\n&lt;coolcode&gt;\nattrfind = re.compile(\nr's*([a-zA-Z_][-.:a-zA-Z_0-9]*)(s*=s*'\nr'('[^']*'|\"[^\"]*\"|[-a-zA-Z0-9./,:;+*%?!&amp;$()_#=~@]*))?')\n&lt;/coolcode&gt;\n\n正则表达式的第二行在遇到形如\n\n&lt;coolcode&gt;\nalt=我是中国人 height=60 src='images/go.gif'&gt;\n&lt;/coolcode&gt;\n\n这样内容为中文不加引号的属性时无法处理。于是稍做修改(我是个大老粗,改得很偷懒,但是好像很管用)\n\n&lt;coolcode&gt;\nattrfind = re.compile(\nr's*([a-zA-Z_][-.:a-zA-Z_0-9]*)(s*=s*'\nr'('[^']*'|\"[^\"]*\"|[^s^'^\"]*))?')\n&lt;/coolcode&gt;\n就能解析中文属性了。","postDate":"2009-06-04 23:01:02","postId":881,"type":"post","status":"publish","imported":true,"file":"881.md"}