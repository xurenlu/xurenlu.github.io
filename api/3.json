{"title":"24小时搭建可用的百度文库抓取与索引系统","zzzContent":"24小时,搭一个文档搜索\n\n#引(fei)言(hua)\n\n话说有一天想到KPI,突然一激灵,想到有一条是\"在ATA上发表有技术深度文章至少一篇\".一个季度过去了,还没开写呢....\n\n绞尽脑汁,咱也不是有技术深度的人啊,怎样才能搞一篇有技术深度的文章咧??\n\n\n想来想去,想写点语言层次的东西吧,又啥都不精.php做得最久,可惜到现在也就能改改简单的扩展,其他python 和go算是略懂,其他的就基本不会了.后来一想,要不,搞个从抓取到搜索,全套服务(喂喂,不要想歪)吧.\n\n然后接下来,就给自己拟定了这么一个课题,要求就是,用大约24个小时的开发时间,完成对百度文库的内容抓取和入库索引,检索服务.当然,一切需要站在巨人的肩膀上,谁叫我是个身高一米六的矮子呢?\n\n#目标\n\n基本目标如下:\n\n + 开发时间要短,控制在24小时.这样就有时间陪娃摆积木,如果她不想摆积木,我还可以看看chinajob    的照片....\n    \n + 尽量利用现有资源.网上有开源的实现,就不要动手自己写(好吧,其实我一开始是想利用万能的淘宝买一份     百度文库的资料回来搭建系统的).原因同上...要有时间陪娃玩耍.\n     \n + 数据量级适中,能演示出效果就好,能在自己的破笔记本上运行,但也不能太小,这样满足不了\"有技术深度\"这个要求;\n     \n + 架构可扩展,万一哪天有个公司说需要类似一套系统,直接卖给他,嗯,biu地一下子,实现迎娶白富美,出任CEO,走上人生巅峰的梦想.(廉政部不会刚好看到吧...)\n\n\n#思路\n好了,接下来,考虑一下如何实现.\n整个系统,先拆分成抓取文档,建索引和提供查询服务三部分.\n    抓取部分,考虑到可实现抓取的代码库比较多,猜想可能有现成的.上github搜了一下,没找着现成的抓百度文库的好的代码.晚上又试了一下.....github打不开了(让我们祝愿病魔早日占胜那位创建gfw的校长!).最后决定还是自己在开源crawl库的基础上写代码.\n    索引和查询部分,其实是都基于一套全文检索的服务上套一个壳,只是查询服务需要提供一个界面而已.这对于我这种套了快10年页面的资深套页面工程师来说,那是so easy.只是,全文检索服务的选型,是一个有(fei)点(chang)恼人的事.\n    在抓取的过程中,有两个重要的事情,一是要避免重复抓取,二是如何记录已经抓取过的文档.避免重复抓取这件事上,一开始是打算用bloom filter来实现,后来觉得开发时间上可能会拉长,就改成将id号存到redis里了.记录已经抓取过的文档,也是尽量从简,就存mysql好了.考虑到python的mysql扩展需要编译,且为了方便扩展,用go来做一个http形式的存取接口,提供和写两个接口).\n    \n    \n#架构设计\n\n    \n    \n    \n    \n    \n\n\n\n","postDate":"2018-01-01 02:03:35","postId":3,"type":"post","status":"publish","imported":false,"file":"24小时搭建可用的百度文库抓取与索引系统.md"}