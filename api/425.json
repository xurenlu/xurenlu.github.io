{"title":"rlucene 0.13释出....","zzzContent":"前一阵偏离了方向，一直在努力地做分词的性能优化。\n后来发现,有时越优化性能反而越差，所以打算改改方向。\n于是挑了一个版本拿出来随便打了一个包，版本号定为0.13，就这 么发出来了。\n这一个月时间才出来了一个版本却还不让我自己满意。不过先放出来吧。\n马上学习一下Ferret，打算在下一个版本开始引入它的一些特性。现在的rlucene实际上还根本不能为检索提供任何实质用处....(我脸皮还真厚吧?)\nRlucene地址:https://rubyforge.org/projects/rlucene/\n更新手记:\n2007.7.3\n1.加入了对网址,数字的预先处理,这类词能正确处理.\n2.autotag.gettags返回的词能自动去重了.\n2007.7.1 今天我改动不少：\n1.分词时引入jcode,效率提高不少.\n2.autotag和segserver改写了,减少重复的操作\n3.用Marshal保存词库数据,启动速度提高不少\n\n2007.6.24 example/demo edition 0.09 将公司的php的基础服务做完之后，忽然很 有成就感,原来以为会很难的东西竟然一周内全盘搞定,权限系统,Cron服务,多mysql server架构问题,all done,非常爽,于是加紧把这个project给改了一下.\n解决了一个Bug:就是在一段中文一段英文的情况下分词时,会丢失中文的最后 一个词.\n但是我认为还是不适合实用.\nto do: 下一步我将从互联网上抓到大约100,000条大文本,然后做分词检测,算出最常见词,在某些应用中会用到.\n2007.6.16 example/demo edition 这是我学完python之后做完分词demo后一边啃ruby 一边做出来的东东。\n可能不太好，只能给大家提供一种分词,索引，搜索的思路罢了。\n慢慢完善之后，在下一版争取加入异常处理之类的。\n这一版我甚至不知道如何加入注释，加\"#\"还是我猜出来的..\n完成后一直还在想为什么ruby没有异常处理,原来ruby其实是有的，只是我没有google 到相应文档而已。","postDate":"2007-07-16 23:27:20","postId":425,"type":"post","status":"publish","imported":true,"file":"425.md"}